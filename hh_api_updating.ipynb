{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating HH.ru Vacancies in ClickHouse\n",
    "This notebook automates the updating of vacancy data from the `vacancies_hh_ru` table in ClickHouse:\n",
    "\n",
    "- Selects non-archived vacancies from ClickHouse.\n",
    "- Requests details for each vacancy in parallel via the HH API.\n",
    "- If the description or status has changed, forms an update.\n",
    "- If a vacancy is not found (404), sets the `deleted=1` flag.\n",
    "- All changes are applied to ClickHouse using ALTER TABLE ... UPDATE.\n",
    "\n",
    "**Technologies:**  \n",
    "`pandas`, `sqlalchemy`, `requests`, `tqdm`, `ThreadPoolExecutor`, ClickHouse, HH API\n",
    "\n",
    "---\n",
    "\n",
    "> Structure: import → load data → update → write changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm \n",
    "from sqlalchemy.sql import text\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from clickhouse_driver import Client\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = os.path.expanduser('~/pet-projects/jupyter-notebooks/config.json')\n",
    "TOKEN_PATH = os.path.expanduser('~/pet-projects/jupyter-notebooks/token.json')\n",
    "BASE_DIR = os.path.expanduser('~/pet-projects/jupyter-notebooks/')\n",
    "DATA_DIR = os.path.expanduser('~/pet-projects/jupyter-notebooks/data/hh_api_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"Load configuration from config.json\"\"\"\n",
    "    try:\n",
    "        with open(CONFIG_PATH, 'r') as config_file:\n",
    "            return json.load(config_file)\n",
    "    except FileNotFoundError:\n",
    "        raise Exception(\"config.json file not found\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(\"Error parsing config.json\")\n",
    "\n",
    "def save_token(token_data):\n",
    "    \"\"\"Save token to file\"\"\"\n",
    "    token_data['saved_at'] = datetime.now().isoformat()\n",
    "    with open(TOKEN_PATH, 'w') as token_file:\n",
    "        json.dump(token_data, token_file)\n",
    "\n",
    "def load_token():\n",
    "    \"\"\"Load existing token\"\"\"\n",
    "    try:\n",
    "        with open(TOKEN_PATH, 'r') as token_file:\n",
    "            token_data = json.load(token_file)\n",
    "            saved_at = datetime.fromisoformat(token_data['saved_at'])\n",
    "            # Check if token has expired (we store for 1 day)\n",
    "            if datetime.now() - saved_at < timedelta(days=1):\n",
    "                return token_data['access_token']\n",
    "    except (FileNotFoundError, json.JSONDecodeError, KeyError):\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def get_access_token(client_id, client_secret):\n",
    "    \"\"\"Get access token from HH.ru API\"\"\"\n",
    "    # First try to load existing token\n",
    "    existing_token = load_token()\n",
    "    if existing_token:\n",
    "        return existing_token\n",
    "\n",
    "    # If token not found or expired, request new one\n",
    "    token_url = 'https://hh.ru/oauth/token'\n",
    "    headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret\n",
    "    }\n",
    "    \n",
    "    response = requests.post(token_url, headers=headers, data=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        token_data = response.json()\n",
    "        save_token({\n",
    "            'access_token': token_data['access_token'],\n",
    "            'saved_at': datetime.now().isoformat()\n",
    "        })\n",
    "        return token_data['access_token']\n",
    "    else:\n",
    "        raise Exception(f\"Error getting token: {response.status_code}, {response.text}\")\n",
    "\n",
    "\n",
    "def create_api_client():\n",
    "    \"\"\"Create API client with loaded credentials\"\"\"\n",
    "    config = load_config()\n",
    "    \n",
    "    client_id = config.get('client_id')\n",
    "    client_secret = config.get('client_secret')\n",
    "    user_email = config.get('user_email')\n",
    "    \n",
    "    if not client_id or not client_secret:\n",
    "        raise Exception(\"client_id or client_secret missing in config.json\")\n",
    "    \n",
    "    access_token = get_access_token(client_id, client_secret)\n",
    "    \n",
    "    return {\n",
    "        'headers': {\n",
    "            'Authorization': f'Bearer {access_token}',\n",
    "            'HH-User-Agent': f'Your_App_Name ({user_email})'\n",
    "        },\n",
    "        'base_url': 'https://api.hh.ru'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancy_details(api_client, vacancy_id):\n",
    "    \"\"\"Get detailed information about a specific vacancy\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"{api_client['base_url']}/vacancies/{vacancy_id}\",\n",
    "        headers=api_client['headers']\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error getting vacancy details: {response.status_code}, {response.text}\")\n",
    "        \n",
    "    return response.json()\n",
    "\n",
    "def mark_vacancy_deleted(vacancy_id, engine):\n",
    "    sql = f\"ALTER TABLE vacancies_hh_ru UPDATE deleted = 1 WHERE id = {vacancy_id}\"\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql))\n",
    "    print(f\"Вакансия {vacancy_id} помечена как deleted\")\n",
    "\n",
    "def get_vacancy_updates_parallel(df_vacancies, api_client, max_workers=5):\n",
    "    \"\"\"\n",
    "    Параллельно скачивает детали вакансий и возвращает список словарей с изменениями.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    not_found_ids = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(get_vacancy_details, api_client, row['id']): row['id'] for idx, row in df_vacancies.iterrows()}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Скачивание деталей\", unit=\"vacancy\"):\n",
    "            vacancy_id = futures[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                new_description = data.get('description', '')\n",
    "                is_archived = int(data.get('archived', False))\n",
    "                row = df_vacancies[df_vacancies['id'] == vacancy_id].iloc[0]\n",
    "                update_fields = {}\n",
    "                if row['description'] != new_description:\n",
    "                    update_fields['description'] = new_description\n",
    "                if row['archived'] != is_archived:\n",
    "                    update_fields['archived'] = is_archived\n",
    "                if update_fields:\n",
    "                    update_fields['id'] = vacancy_id\n",
    "                    updates.append(update_fields)\n",
    "            except Exception as e:\n",
    "                if \"404\" in str(e):\n",
    "                    update_fields = {'id': vacancy_id, 'deleted': 1}\n",
    "                    updates.append(update_fields)\n",
    "                    not_found_ids.append(vacancy_id)\n",
    "                else:\n",
    "                    print(f\"Ошибка для id={vacancy_id}: {e}\")\n",
    "    print(f\"Всего помечено deleted: {len(not_found_ids)}\")\n",
    "    return updates\n",
    "\n",
    "def apply_vacancy_updates_to_clickhouse(updates, engine):\n",
    "    \"\"\"\n",
    "    Применяет изменения к ClickHouse по списку словарей.\n",
    "    \"\"\"\n",
    "    for upd in updates:\n",
    "        set_clause = ', '.join([f\"{k} = :{k}\" for k in upd if k != 'id'])\n",
    "        sql = text(f\"ALTER TABLE vacancies_hh_ru UPDATE {set_clause} WHERE id = :id\")\n",
    "        print(sql)\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(sql, upd)\n",
    "        print(f\"Вакансия {upd['id']} обновлена: {upd}\")\n",
    "    print(f\"Всего обновлено: {len(updates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "# Использую secure native протокол с портом 9440\n",
    "clickhouse_url = f\"clickhouse+native://default:{config['clickhouse_password']}@{config['clickhouse_host']}:9440/default?secure=True\"\n",
    "engine = create_engine(clickhouse_url, connect_args={'connect_timeout': 10, 'send_receive_timeout': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM vacancies_hh_ru WHERE archived = 0 AND created_at < '2025-04-15'\"\n",
    "df_vacancies = pd.read_sql(query, engine)\n",
    "df_vacancies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client = create_api_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique ids: {df_vacancies['id'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = get_vacancy_updates_parallel(df_vacancies, api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_vacancy_updates_to_clickhouse(updates, engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
